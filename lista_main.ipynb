{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "EmU_vMAruot-"
   },
   "outputs": [],
   "source": [
    "## Importing necessary libraries\n",
    "import torch as tor\n",
    "import torch.nn as nn\n",
    "import torch.utils.data\n",
    "import torch.optim as optim\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import math\n",
    "\n",
    "from sklearn.datasets import make_sparse_coded_signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "QQT7jJ2c_24l"
   },
   "outputs": [],
   "source": [
    "class listaUnit(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "        The basic unit of the lista network\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,activation):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.activation = activation\n",
    "\n",
    "    def forward(self,inp,B,S,theta):\n",
    "\n",
    "        C = B + tor.matmul(S,inp)\n",
    "        Z = self.activation(C,theta)\n",
    "\n",
    "        return Z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Dr3wuif9v4r2"
   },
   "outputs": [],
   "source": [
    "class listanet(nn.Module):\n",
    "\n",
    "    \"\"\"\n",
    "        This is the lista network, that takes as input a signal vector and outputs a sparse code\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,activation,n_features,n_components,device):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        self.n = n_features\n",
    "        self.m = n_components\n",
    "\n",
    "        self.activation = activation\n",
    "\n",
    "        ## defining learnable parameters\n",
    "        self.We = nn.Parameter(tor.rand(self.m, self.n).to(device) * 0.001, requires_grad = True)\n",
    "        self.S = nn.Parameter(tor.rand(self.m, self.m).to(device) * 0.001, requires_grad = True)\n",
    "        self.theta = nn.Parameter(tor.rand(self.m, 1).to(device) * 0.001, requires_grad = True)\n",
    "        \n",
    "        self.l1 = listaUnit(self.activation)\n",
    "        self.l2 = listaUnit(self.activation)\n",
    "        self.l3 = listaUnit(self.activation)\n",
    "\n",
    "    def reset_parameters(self):\n",
    "        nn.init.kaiming_uniform_(self.We,a = math.sqrt(5))\n",
    "        nn.init.kaiming_uniform_(self.S,a = math.sqrt(5))\n",
    "        nn.init.uniform_(self.theta,-0.001,0.001)\n",
    "\n",
    "    def forward(self,x):\n",
    "\n",
    "        B =  tor.matmul(self.We,x)\n",
    "\n",
    "        Z0 = self.activation(B,self.theta)\n",
    "\n",
    "        Z1 = self.l1(Z0,B, self.S, self.theta)\n",
    "        Z2 = self.l2(Z1,B, self.S, self.theta)\n",
    "        Z3 = self.l3(Z2,B, self.S, self.theta)\n",
    "\n",
    "        return Z3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "I6ohRPuz2TtS"
   },
   "outputs": [],
   "source": [
    "def soft_threshold(v,theta):\n",
    "\n",
    "    \"\"\"\n",
    "        The soft-thresholding function\n",
    "    \"\"\"\n",
    "\n",
    "    v = tor.sign(v) * tor.max(tor.abs(v) - theta,tor.tensor(0.0).to(device))\n",
    "\n",
    "    return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uS5Cp4cvzAX0"
   },
   "outputs": [],
   "source": [
    "def batch_soft_threshold(v,theta):\n",
    "\n",
    "    \"\"\"\n",
    "        perform soft-thresholding on the entire batch\n",
    "    \"\"\"\n",
    "\n",
    "    batch_size,i,j = v.size()\n",
    "    v1 = v.clone()\n",
    "\n",
    "    for k in range(batch_size):\n",
    "\n",
    "        v1[k,:,:] = soft_threshold(v[k,:,:],theta)\n",
    "\n",
    "    return v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Zi-b71dBOPXX"
   },
   "outputs": [],
   "source": [
    "def getdata(n_features,n_components,n_samples,n_nonzero_coefs,random_state = None,train_size = 0.7):\n",
    "\n",
    "    \"\"\"\n",
    "        Obtain the data of signal, the corresponding dictionary and the sparse codes\n",
    "    \"\"\" \n",
    "\n",
    "    X,Wd,Z = make_sparse_coded_signal(n_samples,n_components,n_features,n_nonzero_coefs,random_state)\n",
    "\n",
    "    mid1 = int(X.shape[1] * (train_size))\n",
    "    mid2 = mid1 + int(X.shape[1] * (1 - train_size))//2\n",
    "\n",
    "    Xtrain = X[:,:mid1]\n",
    "    Xval = X[:,mid1:mid2]\n",
    "    Xtest = X[:,mid2:]\n",
    "    Ztrain = Z[:,:mid1]\n",
    "    Zval = Z[:,mid1:mid2]\n",
    "    Ztest = Z[:,mid2:]\n",
    "\n",
    "    Xtrain,Xtest,Ztrain,Ztest = tor.from_numpy(Xtrain),tor.from_numpy(Xtest),tor.from_numpy(Ztrain),tor.from_numpy(Ztest)\n",
    "    Xval,Zval = tor.from_numpy(Xval),tor.from_numpy(Zval)\n",
    "\n",
    "    return Xtrain,Xval,Xtest,Wd,Ztrain,Zval,Ztest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "d2Lf7Da1IJm8"
   },
   "outputs": [],
   "source": [
    "class dataset(torch.utils.data.Dataset):\n",
    "\n",
    "    \"\"\"\n",
    "        Dataset class\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, phase = \"train\"):\n",
    "\n",
    "        super().__init__()\n",
    "\n",
    "        if(phase == \"train\"):\n",
    "            self.Z = Ztrain\n",
    "            self.X = Xtrain\n",
    "        elif(phase == \"val\"):\n",
    "            self.X = Xval\n",
    "            self.Z = Zval\n",
    "        elif(phase == \"test\"):\n",
    "            self.X = Xtest\n",
    "            self.Z = Ztest\n",
    "\n",
    "\n",
    "        self.data_size = self.X.size(1)\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.data_size\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "\n",
    "        Zi = self.Z[:,idx].unsqueeze(1).type(tor.FloatTensor)\n",
    "        Xi = self.X[:,idx].unsqueeze(1).type(tor.FloatTensor)\n",
    "\n",
    "        return Zi,Xi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "eK-YcopdnXJ7"
   },
   "source": [
    "### Divide the dataset into train, validation and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "z5g_yuTlPW-S"
   },
   "outputs": [],
   "source": [
    "Xtrain,Xval,Xtest,Wd,Ztrain,Zval,Ztest = getdata(100,100,50000,60)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "qI-2ALHEPNnV"
   },
   "source": [
    "### saving the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "ttPBsR6FPSfS",
    "outputId": "b131d576-b556-4c8e-f3d3-51aec638c324"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data loaded\n"
     ]
    }
   ],
   "source": [
    "task = \"load\"\n",
    "\n",
    "if(task == \"save\"):\n",
    "    np.save(\"Xtrain.npy\",Xtrain)\n",
    "    np.save(\"Xval.npy\",Xval)\n",
    "    np.save(\"Xtest.npy\",Xtest)\n",
    "    np.save(\"Wd.npy\",Wd)\n",
    "    np.save(\"Ztrain.npy\",Ztrain)\n",
    "    np.save(\"Zval.npy\",Zval)\n",
    "    np.save(\"Ztest.npy\",Ztest)\n",
    "elif(task == \"load\"):\n",
    "    Xtrain = np.load(\"Xtrain.npy\")\n",
    "    Xval = np.load(\"Xval.npy\")\n",
    "    Xtest = np.load(\"Xtest.npy\")\n",
    "    # Wd = np.load(\"Wd.npy\")\n",
    "    Ztrain = np.load(\"Ztrain.npy\")\n",
    "    Zval = np.load(\"Zval.npy\")\n",
    "    Ztest = np.load(\"Ztest.npy\")\n",
    "\n",
    "    Xtrain,Xtest,Ztrain,Ztest = tor.from_numpy(Xtrain),tor.from_numpy(Xtest),tor.from_numpy(Ztrain),tor.from_numpy(Ztest)\n",
    "    Xval,Zval = tor.from_numpy(Xval),tor.from_numpy(Zval)\n",
    "\n",
    "    print(\"data loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pgLVNRSHnhar"
   },
   "source": [
    "### Create the training set and validation set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ZqjoUIi6QGJ0"
   },
   "outputs": [],
   "source": [
    "trainset = dataset()\n",
    "trainloader = tor.utils.data.DataLoader(trainset,batch_size = 128)\n",
    "\n",
    "valset = dataset(phase = \"val\")\n",
    "valloader = tor.utils.data.DataLoader(valset,batch_size = 128)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X-lDyBx7nl-4"
   },
   "source": [
    "### Set up the network and device configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "9BGDBiA4Q-wW",
    "outputId": "3fcf5beb-6d81-48ec-cf4d-75cd7b02a982"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using:  cuda:0\n"
     ]
    }
   ],
   "source": [
    "device = tor.device(\"cuda:0\" if tor.cuda.is_available() else \"cpu\")\n",
    "print(\"using: \",device)\n",
    "\n",
    "net = listanet(batch_soft_threshold,100,100,device)\n",
    "# criterion = nn.MSELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "scJ6QPev3oqk"
   },
   "outputs": [],
   "source": [
    "def train(net,epochs,lr,reg,dataloaders,reset,save = False):\n",
    "\n",
    "    \"\"\"\n",
    "        Method that performs training given a models\n",
    "    \"\"\"\n",
    "\n",
    "    if(reset):\n",
    "        net.reset_parameters()\n",
    "        print(\"/////////////////////// weights reset \\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\\")\n",
    "\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(net.parameters(), lr = 1e-3,weight_decay = reg)\n",
    "\n",
    "    trainloader,valloader = dataloaders\n",
    "\n",
    "    epoch_losses = []\n",
    "\n",
    "    # with tor.autograd.set_detect_anomaly(True):\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        batch_losses = []\n",
    "\n",
    "        for batch_idx,(z,x) in enumerate(trainloader):\n",
    "\n",
    "            z,x = z.to(device),x.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            out = net(x)\n",
    "            loss = criterion(out,z)\n",
    "\n",
    "            # print(out)\n",
    "            # print(z)\n",
    "            # print(loss)\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            batch_losses.append(loss.item())\n",
    "        \n",
    "        print(\"epoch: \",epoch,\"epoch loss: \",np.mean(batch_losses))\n",
    "\n",
    "        net.eval()\n",
    "\n",
    "        with tor.no_grad():\n",
    "\n",
    "            batch_losses = []\n",
    "            for batch_idx,(z,x) in enumerate(valloader):\n",
    "                \n",
    "                z,x = z.to(device),x.to(device)\n",
    "\n",
    "                out = net(x)\n",
    "\n",
    "                loss = criterion(out,z)\n",
    "\n",
    "                batch_losses.append(loss.item())\n",
    "\n",
    "            print(\"val loss: \",np.mean(batch_losses))\n",
    "\n",
    "        net.train()\n",
    "\n",
    "        print(\"-------------------------------------------------------------------------------------\")\n",
    "\n",
    "        if(save):\n",
    "            state = net.state_dict()\n",
    "            tor.save(state,\"/content/drive/My Drive/datasets/model_chk.pth.tar\")\n",
    "            print(\"******************** saving the model ****************************\")\n",
    "    return epoch_losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "X7p_F6v1rwI5"
   },
   "source": [
    "### Loading a pre-existing model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "1xtUZ5SHszna",
    "outputId": "008f8dd3-4fdf-4f66-e6e5-4bab1f1b76d1"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 13,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = tor.load(\"/content/drive/My Drive/datasets/model_chk.pth.tar\")\n",
    "net.load_state_dict(state)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lIRnUSEjr0hN"
   },
   "source": [
    "### training the model given a set of hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Pd8NHMmv4qhc"
   },
   "outputs": [],
   "source": [
    "epochs = 100\n",
    "lr = 1.38 * 1e-6\n",
    "dataloaders = [trainloader,valloader]\n",
    "reset = False\n",
    "\n",
    "state = tor.load(\"/content/drive/My Drive/datasets/model_chk.pth.tar\")\n",
    "net.load_state_dict(state)\n",
    "_ = train(net,epochs,lr,dataloaders,reset,save = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "JpxdH-b5r8Eh"
   },
   "source": [
    "### Hyper-parameter tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "pO2kVxOz5CSn"
   },
   "outputs": [],
   "source": [
    "epochs = 35\n",
    "rounds = 10\n",
    "\n",
    "reset = True\n",
    "dataloaders = [trainloader,valloader]\n",
    "\n",
    "for count in range(rounds):\n",
    "\n",
    "    lr = 10 ** np.random.uniform(-6,-1)\n",
    "    reg = 10 ** np.random.uniform(-5,-1)\n",
    "\n",
    "    print(\"learning rate: \",lr,\"reg: \",reg,\"---> \",count+1,\"/\",rounds)\n",
    "\n",
    "    _ = train(net,epochs,lr,reg,dataloaders,reset)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "lista1.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
